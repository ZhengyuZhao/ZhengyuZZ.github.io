<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
  <title>Zhengyu Zhao's Homepage</title>

<link rel="stylesheet" href="stylesheets/styles.css">
<link rel="stylesheet" href="stylesheets/stylesheets.css">

<link rel="stylesheet" href="stylesheets/pygment_trac.css">
<meta name="viewport" content="width=device-width">
</head>
  
  
<body>
<div class="wrapper" >
  
<header>
<div>
<img src="images/img_self_2.jpg" border="0" width="80%"><br></div><br>
<h7>Zhengyu Zhao</h7><br>
 <h7 <font style="font-family:隶书" style="text-align:right" style="margin:0 0 20px" size="7"><strong>(赵正宇)</strong></font></h7><br>
z.zhao@cs.ru.nl<br>
<p>
<a href="https://scholar.google.com/citations?user=pC8KpPMAAAAJ">Google Scholar</a><br><br>
  <a href="https://www.researchgate.net/profile/Zhengyu_Zhao4">ResearchGate</a><br><br>
<a href="https://github.com/ZhengyuZhao">GitHub</a><br><br>
<a href="https://www.visualcv.com/pdfs/4161902/">CV</a><br><br>
<a href="https://twitter.com/JeremyZhaozy">Twitter</a><br>
</p>
</header>

<section>

<h2><a id="Biography-page" class="anchor" href="#biography-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>About Me</h2>

<!-- <p>I am a final-year PhD candidate at the <a href="https://www.ru.nl/datascience/">Data Science Group</a>, Radboud University, working with <a href="https://www.ru.nl/english/people/larson-m/">Prof. Martha Larson</a>. 
My research interests include computer vision and image processing. Much of my research experience has concentrated on adversarial examples, scene image understanding, and image forensics.</p> -->
<p>I am a final-year PhD candidate at Radboud University, Netherlands, under the supervision of Prof. Martha Larson. My general research goal is to develop interpretable and explainable machine vision systems.
To this end, my research has concentrated on the tasks where machines can benefit from characteristic properties of human visual perception and interpretation, such as <strong>adversarial examples</strong> and <strong>scene understanding</strong>. I also had good experience in <strong>image forensics</strong>, where, on the contrary, machines dramatically surpass humans in recognizing subtle manipulations.
</p>
<!-- <hr />  -->
  
<h2><a id="Recent News" class="anchor" href="#biography-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>News</h2>
<p>
- <strong>[10/2020]</strong> Our paper about <em>side-channel attack on phone screens</em> is accepted to <strong>NDSS 2021</strong>.<br>
- <strong>[08/2020]</strong> I am awarded the Outstanding Reviewer of <strong>BMVC 2020</strong>!<br>
- <strong>[07/2020]</strong> Our paper about <em>unrestricted adversarial images</em> is accepted to <strong>BMVC 2020</strong>.<br>
- <strong>[07/2020]</strong> We are organizing the 3rd edition of <a href="https://multimediaeval.github.io/editions/2020/tasks/pixelprivacy/">Pixel Privacy Task</a>
  at <strong>MediaEval Benchmark 2020</strong></a>. The task will be focused on deceiving the Blind Image Quality Assessment (BIQA) model by adversarially modifying images.<br>
- <strong>[02/2020]</strong> Our paper about <em>imperceptible adversarial images</em> is accepted to <strong>CVPR 2020</strong>.<br>
<!-- - <strong>[07/2019]</strong> Our reproducibility paper about <em>scene image recognition</em> is accepted to <strong>ACM MM 2019</strong>.<br> -->
- <strong>[04/2019]</strong> Our paper about <em>adversarial queries in image retrieval</em> is accepted to <strong>ICMR 2019</strong>.<br>
- <strong>[07/2018]</strong> Our paper about <em>scene image recognition</em> is accepted to <strong>ACM MM 2018</strong>.<br>
</p>
<!-- <hr />  -->

<h2><a id="publications-pages" class="anchor" href="#publications-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Publications</h2>
<h4>As first author:</h4>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
            <tr>
                           
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/google.PNG' width='224'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2012.11207">
                <papertitle>On Success and Simplicity: A Second Look at Transferable Targeted Attacks</papertitle>
              </a>
              <br>
              <strong>Zhengyu Zhao</strong>, Zhuoran Liu, Martha Larson
              <br>
                <em>arXiv</em>, 2020
<!--               <br>
                <a href="https://www.bmvc2020-conference.com/assets/papers/0099.pdf">Preliminary version</a> published at <em>British Machine Vision Conference (<strong>BMVC</strong>)</em>, 2020 -->
              <br>
              <a href="https://github.com/ZhengyuZhao/Targeted-Tansfer">[Code]</a>
<!--               <p></p> -->
            </td>   
           </tr>     
  

            <tr>
                           
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/illustration.PNG' width='224'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2011.06690">
                <papertitle>Adversarial Robustness Against Image Color Transformation within Parametric Filter Space</papertitle>
              </a>
              <br>
              <strong>Zhengyu Zhao</strong>, Zhuoran Liu, Martha Larson
              <br>
                <em>Under review by a journal</em>, 2020
<!--               <br>
                <a href="https://www.bmvc2020-conference.com/assets/papers/0099.pdf">Preliminary version</a> published at <em>British Machine Vision Conference (<strong>BMVC</strong>)</em>, 2020 -->
              <br>
              <a href="https://github.com/ZhengyuZhao/ACE/tree/master/Journal_version">[Code]</a> <a href="https://www.bmvc2020-conference.com/conference/papers/paper_0099.html">[Video]</a> <a href="https://www.bmvc2020-conference.com/assets/papers/0099.pdf">[Preliminary Version at <strong>BMVC</strong> 2020]</a>
<!--               <p></p> -->
            </td>   
           </tr>   
              
  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/perc.PNG' width='224'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1911.02466">
                <papertitle>Towards Large yet Imperceptible Adversarial Image Perturbations with Perceptual Color Distance</papertitle>
              </a>
              <br>
              <strong>Zhengyu Zhao</strong>, Zhuoran Liu, Martha Larson
              <br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020
              <br>
              <a href="https://github.com/ZhengyuZhao/PerC-Adversarial">[Code]</a> <a href="https://www.youtube.com/watch?v=2j74B_9VaJ8">[Video]</a>
<!--               <p></p> -->
<!--               <p>The monocular depth estimates produced by fully convolutional networks can be used to inform intrinsic image estimation.</p> -->
            </td>
          </tr>    

  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/adired.PNG' width='224'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1807.08624">
                <papertitle>From Volcano to Toyshop: Adaptive Discriminative Region Discovery for Scene Recognition</papertitle>
              </a>
              <br>
              <strong>Zhengyu Zhao</strong>, Martha Larson
              <br>
<!--               <em>arXiv</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
              <em>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</em>, 2018
              <br>
              <a href="https://github.com/ZhengyuZhao/Adi-Red-Scene">[Code]</a> <a href="https://dl.acm.org/citation.cfm?id=3351169">[Reproducibility companion paper at <em><strong>ACM MM</strong></em> 2019]</a>  
<!--               <p></p>

              <a href="https://dl.acm.org/citation.cfm?id=3351169">
                <papertitle>Reproducible Experiments on Adaptive Discriminative Region Discovery for Scene Recognition</papertitle>
              </a>
              <br>
              <strong>Zhengyu Zhao</strong>, Zhuoran Liu, Martha Larson, Ahmet Iscen, Naoko Nitta
              <br>
              (Short companion paper @ <a href="https://project.inria.fr/acmmmreproducibility/">Reproducibility Track</a>) <em><strong>ACM MM</strong></em>, 2019 
              <p></p> -->
              
            </td>
                        
          </tr>    
</tbody></table>
  
<h4>As co-author:</h4>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>  
         <tr>   
            <td style="padding:40px;width:25%;vertical-align:middle">
              <img src='images/screengleaning.PNG' width='180'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2011.09877">
                <papertitle>Screen Gleaning: A Screen Reading TEMPEST Attack on Mobile Devices Exploiting an Electromagnetic Side Channel</papertitle>
              </a>
              <br>
              Zhuoran Liu, Niels Samwel, Léo Weissbart, <strong>Zhengyu Zhao</strong>, Dirk Lauret, Lejla Batina, Martha Larson
              <br>
              <em>The Network and Distributed System Security Symposium (<strong>NDSS</strong>)</em>, 2021
              <br>
              <a href="https://github.com/cescalab/screen_gleaning">[Code]</a>
<!--               <p></p> -->
<!--               <p>The monocular depth estimates produced by fully convolutional networks can be used to inform intrinsic image estimation.</p> -->
            </td>
          </tr>    
  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/PIRE_2.PNG' width='224'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1901.10332">
                <papertitle>Who's Afraid of Adversarial Queries? The Impact of Image Modifications on Content-based Image Retrieval</papertitle>
              </a>
              <br>
              Zhuoran Liu, <strong>Zhengyu Zhao</strong>, Martha Larson
              <br>
              <em>ACM International Conference on Multimedia Retrieval (<strong>ICMR</strong>)</em>, 2019
              <br>
              <a href="https://github.com/liuzrcc/PIRE">[Code]</a>
<!--               <p></p> -->
            </td>
          </tr> 
  
  
</tbody></table>
<!-- <hr />  -->


<h2><a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Professional Services</h2>
<p>
<li>Task co-organizer of <a href="https://multimediaeval.github.io/editions/2020/tasks/pixelprivacy/">Pixel Privacy</a> (2018-present) and <a href="http://www.multimediaeval.org/mediaeval2019/multimediasatellite/">Multimedia Satellite</a> (2018, 2019) at <a href="https://multimediaeval.github.io/about/">MediaEval Benchmark</a>.</li>
<li>Reviewer of BMVC 2020, IEEE Transactions on Information Forensics and Security (TIFS), Pattern Recognition.
<li>Logistics team of ACM MM 2019.<br>
  </p>
<!-- <hr />  -->
 

<h2><a id="new-page" class="anchor" href="#new-page" aria-hidden="true"><span class="octicon octicon-link"></span></a>Honors & Awards</h2>

<li>Outstanding Reviewer Award, BMVC 2020</li>
<li>Student Travel Grant, ACM MM 2018 & 2019</li>
</section>

</div>
<script src="javascripts/scale.fix.js"></script>
</body>

</html>


      
